{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12424794,"sourceType":"datasetVersion","datasetId":7836584}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn, optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nfrom tqdm import tqdm\n\nDATA_DIR = '/kaggle/input/fruit-dataset1/fruit_dataset/fruit_dataset'\nBATCH_SIZE = 32\nNUM_EPOCHS = 30\nIMAGE_SIZE = 224\nVAL_SPLIT = 0.15\nMODEL_SAVE_DIR = './checkpoint'\nLEARNING_RATE = 1e-4\nWEIGHT_DECAY = 1e-5\nEARLY_STOPPING_PATIENCE = 3\nos.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_transforms = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.RandomRotation(25),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nfull_dataset = datasets.ImageFolder(DATA_DIR, transform=train_transforms)\nnum_classes = len(full_dataset.classes)\nval_size = int(VAL_SPLIT * len(full_dataset))\ntrain_size = len(full_dataset) - val_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\nval_dataset.dataset.transform = val_transforms\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\nmodel = models.resnet18(pretrained=True)\nmodel.fc = nn.Sequential(\n    nn.Linear(model.fc.in_features, 256),\n    nn.ReLU(),\n    nn.Dropout(0.3),\n    nn.Linear(256, num_classes)\n)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n\nbest_val_acc = 0.0\nearly_stopping_counter = 0\n\n# === Training Loop ===\nfor epoch in range(NUM_EPOCHS):\n    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n    model.train()\n    train_loss, train_correct = 0.0, 0\n\n    for images, labels in tqdm(train_loader, desc=\"Training\"):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * images.size(0)\n        train_correct += (outputs.argmax(1) == labels).sum().item()\n\n    train_loss /= len(train_loader.dataset)\n    train_acc = train_correct / len(train_loader.dataset)\n\n    # Validation\n    model.eval()\n    val_loss, val_correct = 0.0, 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validating\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item() * images.size(0)\n            val_correct += (outputs.argmax(1) == labels).sum().item()\n\n    val_loss /= len(val_loader.dataset)\n    val_acc = val_correct / len(val_loader.dataset)\n    scheduler.step(val_loss)\n\n    print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n    print(f\"Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n\n    # Save every epoch\n    torch.save(model.state_dict(), f\"{MODEL_SAVE_DIR}/epoch_{epoch+1}.pt\")\n\n    # Save best model\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), f\"{MODEL_SAVE_DIR}/best_model.pt\")\n        print(f\"Best model updated at epoch {epoch+1}!\")\n        early_stopping_counter = 0\n    else:\n        early_stopping_counter += 1\n        if early_stopping_counter >= EARLY_STOPPING_PATIENCE:\n            print(\"Early stopping triggered.\")\n            break\n\nprint(\"\\nTraining complete. Checkpoints saved in './checkpoint'.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-10T07:00:28.758819Z","iopub.execute_input":"2025-07-10T07:00:28.759465Z","iopub.status.idle":"2025-07-10T07:06:53.614618Z","shell.execute_reply.started":"2025-07-10T07:00:28.759440Z","shell.execute_reply":"2025-07-10T07:06:53.613850Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it]\nValidating: 100%|██████████| 7/7 [00:07<00:00,  1.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.7781, Acc: 0.4440\nVal   Loss: 1.1484, Acc: 0.6825\nBest model updated at epoch 1!\n\nEpoch 2/30\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it]\nValidating: 100%|██████████| 7/7 [00:07<00:00,  1.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8332, Acc: 0.8043\nVal   Loss: 0.7181, Acc: 0.8294\nBest model updated at epoch 2!\n\nEpoch 3/30\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it]\nValidating: 100%|██████████| 7/7 [00:07<00:00,  1.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3704, Acc: 0.9256\nVal   Loss: 0.6200, Acc: 0.8436\nBest model updated at epoch 3!\n\nEpoch 4/30\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:46<00:00,  1.23s/it]\nValidating: 100%|██████████| 7/7 [00:07<00:00,  1.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1680, Acc: 0.9774\nVal   Loss: 0.4734, Acc: 0.8863\nBest model updated at epoch 4!\n\nEpoch 5/30\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it]\nValidating: 100%|██████████| 7/7 [00:07<00:00,  1.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0878, Acc: 0.9858\nVal   Loss: 0.5482, Acc: 0.8199\n\nEpoch 6/30\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it]\nValidating: 100%|██████████| 7/7 [00:07<00:00,  1.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0628, Acc: 0.9916\nVal   Loss: 0.5048, Acc: 0.8436\n\nEpoch 7/30\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it]\nValidating: 100%|██████████| 7/7 [00:07<00:00,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0371, Acc: 0.9967\nVal   Loss: 0.4873, Acc: 0.8626\nEarly stopping triggered.\n\nTraining complete. Checkpoints saved in './checkpoint'.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn, optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom tqdm import tqdm\n\nDATA_DIR = '/kaggle/input/fruit-dataset1/fruit_dataset/fruit_dataset'\nBATCH_SIZE = 32\nNUM_EPOCHS = 50\nIMAGE_SIZE = 224\nVAL_SPLIT = 0.15\nMODEL_SAVE_DIR = './checkpoint1'\nLEARNING_RATE = 1e-3  # Higher initial learning rate\nWEIGHT_DECAY = 1e-4\nEARLY_STOPPING_PATIENCE = 8\nos.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Simplified data augmentation - too much augmentation was hurting performance\ntrain_transforms = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.RandomRotation(15),  # Reduced rotation\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet normalization\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n\nfull_dataset = datasets.ImageFolder(DATA_DIR, transform=train_transforms)\nnum_classes = len(full_dataset.classes)\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Class names: {full_dataset.classes}\")\n\nval_size = int(VAL_SPLIT * len(full_dataset))\ntrain_size = len(full_dataset) - val_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\n\nval_dataset.dataset.transform = val_transforms\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\nprint(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n\nclass FruitClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(FruitClassifier, self).__init__()\n        \n        self.features = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n            \n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n            \n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n            \n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n        )\n        \n        # Global Average Pooling instead of large linear layers\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        \n        # Classification layers\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)\n        )\n        \n        # Initialize weights\n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\nmodel = FruitClassifier(num_classes).to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n# Learning rate scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n\n# Training tracking\nbest_val_acc = 0.0\nearly_stopping_counter = 0\ntrain_losses = []\nval_losses = []\ntrain_accs = []\nval_accs = []\n\nprint(\"Starting training...\")\nprint(f\"Device: {device}\")\n\nfor epoch in range(NUM_EPOCHS):\n    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n    \n    # Training phase\n    model.train()\n    train_loss = 0.0\n    train_correct = 0\n    train_total = 0\n    \n    for batch_idx, (images, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        \n        # Gradient clipping\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        \n        train_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        train_total += labels.size(0)\n        train_correct += (predicted == labels).sum().item()\n        \n        # Print progress every 10 batches\n        if batch_idx % 10 == 0:\n            print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')\n    \n    # Calculate training metrics\n    train_loss = train_loss / len(train_loader)\n    train_acc = train_correct / train_total\n    \n    # Validation phase\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    \n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validating\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n    \n    val_loss = val_loss / len(val_loader)\n    val_acc = val_correct / val_total\n    \n    # Update learning rate\n    scheduler.step()\n    \n    # Store metrics\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_accs.append(train_acc)\n    val_accs.append(val_acc)\n    \n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n    print(f\"Overfitting gap: {train_acc - val_acc:.4f}\")\n    \n    # Save best model\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'best_val_acc': best_val_acc,\n            'train_losses': train_losses,\n            'val_losses': val_losses,\n            'train_accs': train_accs,\n            'val_accs': val_accs\n        }, f\"{MODEL_SAVE_DIR}/best_model.pt\")\n        print(f\"Best model updated! Val Acc: {val_acc:.4f}\")\n        early_stopping_counter = 0\n    else:\n        early_stopping_counter += 1\n    \n    # Early stopping\n    if early_stopping_counter >= EARLY_STOPPING_PATIENCE:\n        print(\"Early stopping triggered.\")\n        break\n    \n    # Save checkpoint every 5 epochs\n    if (epoch + 1) % 5 == 0:\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'best_val_acc': best_val_acc,\n        }, f\"{MODEL_SAVE_DIR}/checkpoint_epoch_{epoch+1}.pt\")\n\nprint(f\"\\nTraining complete!\")\nprint(f\"Best validation accuracy: {best_val_acc:.4f}\")\nprint(f\"Model saved to {MODEL_SAVE_DIR}/best_model.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T08:45:35.580553Z","iopub.execute_input":"2025-07-10T08:45:35.581473Z","iopub.status.idle":"2025-07-10T08:59:49.967495Z","shell.execute_reply.started":"2025-07-10T08:45:35.581442Z","shell.execute_reply":"2025-07-10T08:59:49.966500Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 10\nClass names: ['Apple', 'Banana', 'Grapes', 'Guava', 'Mango', 'Orange', 'Papaya', 'Pomegranate', 'Strawberry', 'Watermelon']\nTrain samples: 1196, Val samples: 211\nStarting training...\nDevice: cuda\n\nEpoch 1/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:57,  1.55s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 2.2994\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:08<00:20,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 2.0264\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:11,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 2.1424\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:20<00:04,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.9110\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:23<00:00,  1.59it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.0236, Train Acc: 0.2483\nVal Loss: 1.8813, Val Acc: 0.3223\nOverfitting gap: -0.0739\nBest model updated! Val Acc: 0.3223\n\nEpoch 2/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<01:02,  1.68s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.6735\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:12,  2.18it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.8441\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:09,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.5808\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:03,  1.92it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.7529\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:23<00:00,  1.64it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.7716, Train Acc: 0.3119\nVal Loss: 1.8499, Val Acc: 0.3223\nOverfitting gap: -0.0104\n\nEpoch 3/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:44,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.7123\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:15,  1.73it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.6259\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:15,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.7006\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:05,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.8855\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:23<00:00,  1.59it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.7014, Train Acc: 0.3294\nVal Loss: 1.8428, Val Acc: 0.3697\nOverfitting gap: -0.0402\nBest model updated! Val Acc: 0.3697\n\nEpoch 4/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<01:01,  1.66s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.6253\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:18,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.8434\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:09,  1.74it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.5865\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:03,  2.02it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.6040\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:23<00:00,  1.65it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6354, Train Acc: 0.3595\nVal Loss: 1.6206, Val Acc: 0.3602\nOverfitting gap: -0.0007\n\nEpoch 5/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:44,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.4639\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:14,  1.84it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.6367\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:10,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.6556\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:03,  1.92it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.6622\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.68it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6424, Train Acc: 0.3687\nVal Loss: 1.9627, Val Acc: 0.3033\nOverfitting gap: 0.0654\n\nEpoch 6/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:50,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.8522\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:09<00:23,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.7028\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:14<00:08,  1.97it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.6517\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:03,  2.25it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.6747\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.70it/s]\nValidating: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6234, Train Acc: 0.3545\nVal Loss: 1.8869, Val Acc: 0.2891\nOverfitting gap: 0.0654\n\nEpoch 7/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:53,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.4696\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:16,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.4794\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:11,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.6236\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:04,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.5024\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:21<00:00,  1.77it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5863, Train Acc: 0.3604\nVal Loss: 1.5826, Val Acc: 0.4218\nOverfitting gap: -0.0614\nBest model updated! Val Acc: 0.4218\n\nEpoch 8/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:52,  1.42s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.4724\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:15,  1.77it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.6717\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:07,  2.23it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.7580\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:05,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.5782\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:23<00:00,  1.64it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6743, Train Acc: 0.3512\nVal Loss: 1.9685, Val Acc: 0.3081\nOverfitting gap: 0.0431\n\nEpoch 9/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:48,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.5836\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:13,  2.02it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.4739\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:09,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.7589\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:03,  1.78it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.7873\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.70it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5944, Train Acc: 0.3746\nVal Loss: 1.6582, Val Acc: 0.3412\nOverfitting gap: 0.0333\n\nEpoch 10/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:42,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.6546\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:14,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.6253\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:08,  1.99it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.4885\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:04,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.4182\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.66it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5514, Train Acc: 0.3855\nVal Loss: 1.6824, Val Acc: 0.3081\nOverfitting gap: 0.0774\n\nEpoch 11/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:52,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.4328\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:14,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.5188\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:10,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.6509\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:05,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.5121\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:23<00:00,  1.64it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5381, Train Acc: 0.3905\nVal Loss: 2.4116, Val Acc: 0.2085\nOverfitting gap: 0.1819\n\nEpoch 12/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<01:00,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.9693\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:15,  1.77it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.3727\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:08,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.2925\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:04,  1.70it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.4904\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.65it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5953, Train Acc: 0.3788\nVal Loss: 1.8427, Val Acc: 0.3128\nOverfitting gap: 0.0660\n\nEpoch 13/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:38,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.5240\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:13,  1.97it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.3793\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:11<00:07,  2.20it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.5240\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:17<00:03,  1.88it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.5441\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.70it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4948, Train Acc: 0.3946\nVal Loss: 1.5710, Val Acc: 0.3555\nOverfitting gap: 0.0392\n\nEpoch 14/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:51,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.4471\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:16,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.7164\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:07,  2.21it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.7784\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:04,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.5227\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:21<00:00,  1.73it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5740, Train Acc: 0.3712\nVal Loss: 1.4260, Val Acc: 0.4550\nOverfitting gap: -0.0837\nBest model updated! Val Acc: 0.4550\n\nEpoch 15/50\nLearning Rate: 0.001000\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:00<00:31,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.6789\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:14,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.5811\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:11<00:08,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.6381\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:05,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.5485\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.65it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5621, Train Acc: 0.3687\nVal Loss: 1.6926, Val Acc: 0.3175\nOverfitting gap: 0.0512\n\nEpoch 16/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<01:01,  1.66s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.4748\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:19,  1.41it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.5084\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:07,  2.23it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.3318\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:03,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.3607\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.66it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4774, Train Acc: 0.4222\nVal Loss: 1.3758, Val Acc: 0.4550\nOverfitting gap: -0.0327\n\nEpoch 17/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<01:09,  1.87s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.5946\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:14,  1.91it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.5978\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:08,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.5191\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:03,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.6890\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.67it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4355, Train Acc: 0.4214\nVal Loss: 1.3660, Val Acc: 0.4550\nOverfitting gap: -0.0336\n\nEpoch 18/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:55,  1.51s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.2027\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:16,  1.67it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 2.0586\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:12,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.4557\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:03,  1.88it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.2164\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.69it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4161, Train Acc: 0.4365\nVal Loss: 1.3507, Val Acc: 0.4787\nOverfitting gap: -0.0422\nBest model updated! Val Acc: 0.4787\n\nEpoch 19/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<01:12,  1.95s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.5475\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:14,  1.89it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.2295\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:11,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.5762\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:04,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.3244\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.68it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4368, Train Acc: 0.4398\nVal Loss: 1.3474, Val Acc: 0.4645\nOverfitting gap: -0.0247\n\nEpoch 20/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:02<01:21,  2.20s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.4681\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:16,  1.68it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.4295\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:10,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.3092\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:03,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.6112\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.72it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4060, Train Acc: 0.4465\nVal Loss: 1.3551, Val Acc: 0.4408\nOverfitting gap: 0.0057\n\nEpoch 21/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:51,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.2088\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:16,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.5100\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:15,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.3200\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:03,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.1685\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.68it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3776, Train Acc: 0.4624\nVal Loss: 1.3236, Val Acc: 0.4739\nOverfitting gap: -0.0116\n\nEpoch 22/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:49,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.2597\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:09<00:23,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.2385\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:15<00:10,  1.67it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.4529\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.4006\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:24<00:00,  1.57it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3931, Train Acc: 0.4298\nVal Loss: 1.3367, Val Acc: 0.4502\nOverfitting gap: -0.0205\n\nEpoch 23/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:59,  1.61s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.1666\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:13,  1.97it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.5766\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:08,  2.02it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.6829\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:05,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.2855\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:23<00:00,  1.64it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4026, Train Acc: 0.4415\nVal Loss: 1.3201, Val Acc: 0.4882\nOverfitting gap: -0.0467\nBest model updated! Val Acc: 0.4882\n\nEpoch 24/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:51,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.4599\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:17,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.3390\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:14<00:14,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.3374\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:03,  2.07it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.2912\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:23<00:00,  1.63it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3922, Train Acc: 0.4548\nVal Loss: 1.3278, Val Acc: 0.4834\nOverfitting gap: -0.0286\n\nEpoch 25/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:48,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.3261\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:15,  1.77it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.6791\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:09,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.6227\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:04,  1.41it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.2884\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.69it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3688, Train Acc: 0.4741\nVal Loss: 1.3357, Val Acc: 0.4502\nOverfitting gap: 0.0238\n\nEpoch 26/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:54,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.4061\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:09<00:23,  1.17it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.2620\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:14<00:08,  2.05it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.2882\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:03,  2.09it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.2209\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:23<00:00,  1.63it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3792, Train Acc: 0.4565\nVal Loss: 1.3485, Val Acc: 0.4360\nOverfitting gap: 0.0205\n\nEpoch 27/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:56,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.5521\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:06<00:15,  1.74it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.3610\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:11,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.3745\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:04,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.5807\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.70it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3840, Train Acc: 0.4448\nVal Loss: 1.3046, Val Acc: 0.4787\nOverfitting gap: -0.0339\n\nEpoch 28/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:00<00:35,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.5414\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:14,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.6769\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:08,  2.01it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.2786\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:03,  1.97it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.1893\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:21<00:00,  1.76it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3468, Train Acc: 0.4540\nVal Loss: 1.3196, Val Acc: 0.4550\nOverfitting gap: -0.0010\n\nEpoch 29/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<00:48,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.2718\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:23,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.3270\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:09,  1.74it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.1802\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:04,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.4447\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.68it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3456, Train Acc: 0.4507\nVal Loss: 1.3396, Val Acc: 0.4455\nOverfitting gap: 0.0052\n\nEpoch 30/50\nLearning Rate: 0.000100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<01:00,  1.63s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.2055\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:15,  1.72it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.3548\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:13<00:09,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.1762\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:19<00:03,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.2486\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.66it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3421, Train Acc: 0.4674\nVal Loss: 1.2825, Val Acc: 0.4787\nOverfitting gap: -0.0113\n\nEpoch 31/50\nLearning Rate: 0.000010\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 1/38 [00:01<01:13,  1.99s/it]","output_type":"stream"},{"name":"stdout","text":"Batch 0, Loss: 1.1808\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 11/38 [00:07<00:12,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 10, Loss: 1.3348\n","output_type":"stream"},{"name":"stderr","text":"Training:  55%|█████▌    | 21/38 [00:12<00:07,  2.25it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 20, Loss: 1.7075\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|████████▏ | 31/38 [00:18<00:04,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"Batch 30, Loss: 1.1653\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 38/38 [00:22<00:00,  1.70it/s]\nValidating: 100%|██████████| 7/7 [00:04<00:00,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3419, Train Acc: 0.4749\nVal Loss: 1.2753, Val Acc: 0.4645\nOverfitting gap: 0.0105\nEarly stopping triggered.\n\nTraining complete!\nBest validation accuracy: 0.4882\nModel saved to ./checkpoint1/best_model.pt\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nimport sys\n\nMODEL_PATH = './checkpoint1/best_model.pt'\nIMAGE_PATH = '/kaggle/input/fruit-dataset1/mango.jpg'\nIMAGE_SIZE = 224\nCLASS_NAMES = ['Apple', 'Banana', 'Grapes', 'Guava', 'Mango', 'Orange', 'Papaya', 'Pomegranate', 'Strawberry', 'Watermelon']\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# === Preprocessing Transform (same as validation transform) ===\ntransform = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], \n                         [0.229, 0.224, 0.225])\n])\n\nimport torch.nn as nn\n\nclass FruitClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(FruitClassifier, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, 2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# === Load Model ===\nmodel = FruitClassifier(num_classes=len(CLASS_NAMES))\ncheckpoint = torch.load(MODEL_PATH, map_location=device)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.to(device)\nmodel.eval()\n\nif not os.path.exists(IMAGE_PATH):\n    print(f\"Error: Image file '{IMAGE_PATH}' does not exist.\")\n    sys.exit(1)\n\nimage = Image.open(IMAGE_PATH).convert('RGB')\nimage = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n\nwith torch.no_grad():\n    outputs = model(image)\n    _, predicted = torch.max(outputs, 1)\n    predicted_class = CLASS_NAMES[predicted.item()]\n\nprint(f\"Predicted Fruit: {predicted_class}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T09:19:30.974240Z","iopub.execute_input":"2025-07-10T09:19:30.974574Z","iopub.status.idle":"2025-07-10T09:19:31.153294Z","shell.execute_reply.started":"2025-07-10T09:19:30.974546Z","shell.execute_reply":"2025-07-10T09:19:31.152407Z"}},"outputs":[{"name":"stdout","text":"Predicted Fruit: Mango\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms, models\nfrom PIL import Image\nimport os\n\nMODEL_PATH = './checkpoint/best_model.pt'\nIMAGE_PATH = '/kaggle/input/fruit-dataset1/apple.jpeg'  \nIMAGE_SIZE = 224\nCLASS_NAMES = ['Apple', 'Banana', 'Grapes', 'Guava', 'Mango', 'Orange', 'Peach', 'Pomegranate', 'Strawberry', 'Watermelon']  \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntransform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\n# === Load Model ===\nmodel = models.resnet18(pretrained=False)\nmodel.fc = torch.nn.Sequential(\n    torch.nn.Linear(model.fc.in_features, 256),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.3),\n    torch.nn.Linear(256, len(CLASS_NAMES))\n)\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=device))\nmodel.to(device)\nmodel.eval()\n\n# === Load and Preprocess Image ===\nimage = Image.open(IMAGE_PATH).convert('RGB')\ninput_tensor = transform(image).unsqueeze(0).to(device)\n\n# === Inference ===\nwith torch.no_grad():\n    output = model(input_tensor)\n    predicted_idx = output.argmax(1).item()\n    predicted_class = CLASS_NAMES[predicted_idx]\n\nprint(f\"Predicted Fruit: {predicted_class}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T07:34:38.256854Z","iopub.execute_input":"2025-07-10T07:34:38.257387Z","iopub.status.idle":"2025-07-10T07:34:48.331144Z","shell.execute_reply.started":"2025-07-10T07:34:38.257360Z","shell.execute_reply":"2025-07-10T07:34:48.329912Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/424467573.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLASS_NAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m )\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoint/best_model.pt'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './checkpoint/best_model.pt'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nimport os\n\n# Create a zip archive of the checkpoint folder\nshutil.make_archive('/kaggle/working/checkpoint_backup1', 'zip', '/kaggle/working/checkpoint1')\n\n# The zip file will be saved as checkpoint_backup.zip in /kaggle/working/\n# You can then download it from the Kaggle interface","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T09:20:04.911918Z","iopub.execute_input":"2025-07-10T09:20:04.912263Z","iopub.status.idle":"2025-07-10T09:22:14.378261Z","shell.execute_reply.started":"2025-07-10T09:20:04.912239Z","shell.execute_reply":"2025-07-10T09:22:14.377469Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/checkpoint_backup1.zip'"},"metadata":{}}],"execution_count":7}]}