{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfclvf3PY8Y1",
        "outputId": "dd305c39-9240-419b-b93d-a4c1368f245a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-vision in /usr/local/lib/python3.11/dist-packages (3.10.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2025.6.15)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: deepface in /usr/local/lib/python3.11/dist-packages (0.0.93)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (11.2.1)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.18.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.8.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.1.1)\n",
            "Requirement already satisfied: flask-cors>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (6.0.1)\n",
            "Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (1.0.0)\n",
            "Requirement already satisfied: retina-face>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (0.0.17)\n",
            "Requirement already satisfied: fire>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (0.7.0)\n",
            "Requirement already satisfied: gunicorn>=20.1.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (23.0.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface) (3.1.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (3.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (1.5.1)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (4.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2025.6.15)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install & Authenticate\n",
        "!pip install --upgrade google-cloud-vision\n",
        "!pip install opencv-python deepface\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import json\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision_v1 import types\n",
        "from deepface import DeepFace\n",
        "\n",
        "doc_image_path = \"/content/drive/MyDrive/proj/id.jpg\"\n",
        "ref_image_path = \"/content/drive/MyDrive/proj/target1.jpg\""
      ],
      "metadata": {
        "id": "6mHvSBuoZAVN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shared variable\n",
        "shared_result = {}\n",
        "\n",
        "# -----------------------------\n",
        "# Thread 1: Face Comparison\n",
        "# -----------------------------\n",
        "def face_thread():\n",
        "    global shared_result\n",
        "\n",
        "    def extract_face_opencv(image_path, output_path):\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            print(f\"‚ùå Could not load image: {image_path}\")\n",
        "            return None\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "\n",
        "        if len(faces) == 0:\n",
        "            print(f\"‚ùå No face detected in {image_path}\")\n",
        "            return None\n",
        "\n",
        "        for (x, y, w, h) in faces[:1]:\n",
        "            face = img[y:y+h, x:x+w]\n",
        "            cv2.imwrite(output_path, face)\n",
        "            return output_path\n",
        "\n",
        "        return None\n",
        "\n",
        "    def compare_faces(face1_path, face2_path):\n",
        "        result = DeepFace.verify(\n",
        "            img1_path=face1_path,\n",
        "            img2_path=face2_path,\n",
        "            model_name=\"ArcFace\",\n",
        "            detector_backend=\"retinaface\",\n",
        "            enforce_detection=False\n",
        "        )\n",
        "        distance = round(result[\"distance\"], 4)\n",
        "        return {\n",
        "            \"match\": result[\"verified\"],\n",
        "            \"distance\": distance,\n",
        "            \"similarity\": round((1 - distance), 4)\n",
        "        }\n",
        "\n",
        "    def show_faces_side_by_side(img1_path, img2_path, title1=\"Doc Face\", title2=\"Ref Face\"):\n",
        "        img1 = cv2.imread(img1_path)\n",
        "        img2 = cv2.imread(img2_path)\n",
        "        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(img1)\n",
        "        plt.title(title1)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(img2)\n",
        "        plt.title(title2)\n",
        "        plt.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Perform extraction\n",
        "    doc_face = extract_face_opencv(doc_image_path, \"/content/drive/MyDrive/proj/doc_face.jpg\")\n",
        "    ref_face = extract_face_opencv(ref_image_path, \"/content/drive/MyDrive/proj/ref_face.jpg\")\n",
        "\n",
        "    # Perform comparison and display\n",
        "    if doc_face and ref_face:\n",
        "        shared_result = compare_faces(doc_face, ref_face)\n",
        "        print(\"\\n[Face Thread Result]\")\n",
        "        print(shared_result)\n",
        "\n",
        "        # ‚úÖ Display faces after comparison\n",
        "        show_faces_side_by_side(doc_face, ref_face)\n",
        "\n",
        "    else:\n",
        "        shared_result = {\"match\": False, \"distance\": None, \"similarity\": None}\n",
        "        print(\"‚ùå Face extraction failed.\")\n"
      ],
      "metadata": {
        "id": "qYJkXb9lZCys"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Thread 2: OCR + Field Extraction\n",
        "# -----------------------------\n",
        "def ocr_thread():\n",
        "    global shared_result\n",
        "\n",
        "    # Wait for face_thread to complete\n",
        "    face_thread_handle.join()\n",
        "\n",
        "    key_path = \"/content/drive/MyDrive/proj/ocr-proj-464311-962bfb48b8cc.json\"\n",
        "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = key_path\n",
        "\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    with io.open(doc_image_path, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "    image = types.Image(content=content)\n",
        "    response = client.text_detection(image=image)\n",
        "    texts = response.text_annotations\n",
        "    full_text = texts[0].description if texts else \"\"\n",
        "\n",
        "    # ‚úÖ Save and print raw OCR extracted text for debugging\n",
        "    raw_text_path = os.path.splitext(doc_image_path)[0] + \"_ocr_raw.txt\"\n",
        "    with open(raw_text_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(full_text)\n",
        "    print(f\"\\nüìù Raw OCR Text saved to: {raw_text_path}\")\n",
        "    print(\"\\n---- OCR Extracted Text ----\")\n",
        "    print(full_text)\n",
        "\n",
        "\n",
        "    def detect_language(text):\n",
        "        if re.search(r'[\\u4e00-\\u9fff]', text): return \"chinese\"\n",
        "        elif re.search(r'[\\u0600-\\u06FF]', text): return \"urdu\"\n",
        "        return \"english_or_default\"\n",
        "\n",
        "    def extract_pakistani_fields(text):\n",
        "      data = {}\n",
        "      lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
        "      joined = \"\\n\".join(lines)\n",
        "\n",
        "      if \"passport\" in joined.lower():\n",
        "          data[\"document_type\"] = \"Passport\"\n",
        "\n",
        "          # --- Passport Number (Robust Logic) ---\n",
        "          for i in range(len(lines)):\n",
        "              current = lines[i].lower()\n",
        "\n",
        "              # Case 1: line is exactly \"passport number\"\n",
        "              if \"passport number\" in current and i + 1 < len(lines):\n",
        "                  candidate = lines[i + 1].strip()\n",
        "                  if re.match(r'^[A-Z]{1,2}\\d{6,9}$', candidate):\n",
        "                      data[\"passport_number\"] = candidate\n",
        "                      break\n",
        "\n",
        "              # Case 2: line is \"passport\", next is \"number\", next is actual number\n",
        "              if \"passport\" in current and i + 2 < len(lines):\n",
        "                  if \"number\" in lines[i + 1].lower():\n",
        "                      candidate = lines[i + 2].strip()\n",
        "                      if re.match(r'^[A-Z]{1,2}\\d{6,9}$', candidate):\n",
        "                          data[\"passport_number\"] = candidate\n",
        "                          break\n",
        "\n",
        "          # --- Fallback: Match anywhere in the full text ---\n",
        "          if \"passport_number\" not in data:\n",
        "              fallback = re.search(r'\\b[A-Z]{1,2}\\d{6,9}\\b', joined)\n",
        "              if fallback:\n",
        "                  data[\"passport_number\"] = fallback.group()\n",
        "\n",
        "\n",
        "          # --- CNIC inside passport ---\n",
        "          cnic_match = re.search(r'\\b\\d{5}-\\d{7}-\\d\\b', joined.replace(\"O\", \"0\"))\n",
        "          if cnic_match:\n",
        "              data[\"id_number\"] = cnic_match.group()\n",
        "\n",
        "          # --- Given & Surname ---\n",
        "          for i in range(len(lines)):\n",
        "              if \"surname\" in lines[i].lower():\n",
        "                  for j in range(i + 1, min(i + 4, len(lines))):\n",
        "                      candidate = lines[j].strip()\n",
        "                      if \"code\" in candidate.lower() or candidate == \"PAK\":\n",
        "                          continue\n",
        "                      if re.match(r'^[A-Z ]+$', candidate) and len(candidate) > 2:\n",
        "                          data[\"last_name\"] = candidate.title()\n",
        "                          break\n",
        "\n",
        "              if \"given names\" in lines[i].lower() and i + 1 < len(lines):\n",
        "                  if re.match(r'^[A-Z ]+$', lines[i + 1]):\n",
        "                      data[\"first_name\"] = lines[i + 1].title()\n",
        "\n",
        "          # --- MRZ Name Fallback ---\n",
        "          mrz_lines = [line for line in lines if re.match(r'^<PAK[A-Z<]+$', line)]\n",
        "          if mrz_lines:\n",
        "              name_parts = mrz_lines[0].replace(\"<PAK\", \"\").split(\"<<\")\n",
        "              if len(name_parts) >= 2:\n",
        "                  surname = name_parts[0].replace(\"<\", \"\").strip().title()\n",
        "                  given_name = name_parts[1].replace(\"<\", \"\").strip().title()\n",
        "                  if \"last_name\" not in data:\n",
        "                      data[\"last_name\"] = surname\n",
        "                  if \"first_name\" not in data:\n",
        "                      data[\"first_name\"] = given_name\n",
        "\n",
        "          # --- Gender ---\n",
        "          gender_match = re.search(r'\\bSex[\\s:\\n]*(M|F)\\b', joined, re.IGNORECASE)\n",
        "          if gender_match:\n",
        "              data[\"gender\"] = gender_match.group(1).upper()\n",
        "\n",
        "          # --- DOB ---\n",
        "          dob_match = re.search(r'Date of Birth[\\s:\\n]*([0-9]{2} [A-Z]{3} [0-9]{4})', joined, re.IGNORECASE)\n",
        "          if dob_match:\n",
        "              data[\"date_of_birth\"] = dob_match.group(1).strip()\n",
        "\n",
        "          # --- Issue & Expiry Dates ---\n",
        "          issue_match = re.search(r'Date of Issue[\\s:\\n]*([0-9]{2} [A-Z]{3} [0-9]{4})', joined, re.IGNORECASE)\n",
        "          expiry_match = re.search(r'Date of Expiry[\\s:\\n]*([0-9]{2} [A-Z]{3} [0-9]{4})', joined, re.IGNORECASE)\n",
        "          if issue_match:\n",
        "              data[\"issue_date\"] = issue_match.group(1).strip()\n",
        "          if expiry_match:\n",
        "              data[\"expiry_date\"] = expiry_match.group(1).strip()\n",
        "\n",
        "          # --- Husband / Father Name ---\n",
        "          for i in range(len(lines)):\n",
        "              if \"place of birth\" in lines[i].lower():\n",
        "                  for j in range(i - 1, max(0, i - 4), -1):\n",
        "                      if re.match(r'^[A-Z ]{5,}$', lines[j]):\n",
        "                          data[\"father_or_husband_name\"] = lines[j].title()\n",
        "                          break\n",
        "\n",
        "      elif \"identity card\" in joined.lower():\n",
        "          data[\"document_type\"] = \"ID Card\"\n",
        "\n",
        "          if \"pakistan\" in joined.lower():\n",
        "              data[\"nationality\"] = \"Pakistan\"\n",
        "\n",
        "          id_match = re.search(r'\\b\\d{5}-\\d{7}-\\d\\b', joined)\n",
        "          if id_match:\n",
        "              data[\"id_number\"] = id_match.group()\n",
        "\n",
        "          gender_match = re.search(r'\\b(M|F|X)\\b', joined)\n",
        "          if gender_match:\n",
        "              data[\"gender\"] = gender_match.group()\n",
        "\n",
        "          dob_match = re.search(r'Date of Birth[\\s:\\n]*([\\d./-]{8,10})', joined)\n",
        "          if dob_match:\n",
        "              data[\"date_of_birth\"] = dob_match.group(1)\n",
        "\n",
        "          issue_match = re.search(r'Date of Issue[\\s:\\n]*([\\d./-]{8,10})', joined)\n",
        "          if issue_match:\n",
        "              data[\"issue_date\"] = issue_match.group(1)\n",
        "\n",
        "          expiry_match = re.search(r'Date of Expiry[\\s:\\n]*([\\d./-]{8,10})', joined)\n",
        "          if expiry_match:\n",
        "              data[\"expiry_date\"] = expiry_match.group(1)\n",
        "\n",
        "          name_lines = []\n",
        "          for i, line in enumerate(lines):\n",
        "              if line.lower().startswith(\"name\") and i + 1 < len(lines):\n",
        "                  name_lines.append(lines[i + 1])\n",
        "          if name_lines:\n",
        "              name_parts = name_lines[0].split()\n",
        "              if len(name_parts) == 1:\n",
        "                  data[\"first_name\"] = name_parts[0]\n",
        "              elif len(name_parts) == 2:\n",
        "                  data[\"first_name\"], data[\"last_name\"] = name_parts\n",
        "              elif len(name_parts) >= 3:\n",
        "                  data[\"first_name\"] = name_parts[0]\n",
        "                  data[\"middle_name\"] = \" \".join(name_parts[1:-1])\n",
        "                  data[\"last_name\"] = name_parts[-1]\n",
        "\n",
        "          urdu_lines = [line for line in lines if re.search(r'[\\u0600-\\u06FF]', line)]\n",
        "          if urdu_lines:\n",
        "              if len(urdu_lines) == 1:\n",
        "                  data[\"urdu_name\"] = urdu_lines[0]\n",
        "              elif len(urdu_lines) >= 2:\n",
        "                  data[\"urdu_name\"] = urdu_lines[0]\n",
        "                  data[\"urdu_father_name\"] = urdu_lines[1]\n",
        "\n",
        "      elif \"driving license\" in joined.lower() or \"driver\" in joined.lower():\n",
        "          data[\"document_type\"] = \"Driving License\"\n",
        "\n",
        "      else:\n",
        "          data[\"document_type\"] = \"Unknown\"\n",
        "\n",
        "      if \"pakistan\" in joined.lower() and \"nationality\" not in data:\n",
        "          data[\"nationality\"] = \"Pakistan\"\n",
        "\n",
        "      return data\n",
        "\n",
        "\n",
        "    def extract_chinese_fields(text):\n",
        "      data = {\"document_type\": \"ID Card\"}\n",
        "      lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
        "      joined = \"\\n\".join(lines)\n",
        "\n",
        "      # ‚úÖ Detect if it's a Chinese Passport\n",
        "      if \"PASSPORT\" in joined.upper() and \"CHINA\" in joined.upper():\n",
        "          data[\"document_type\"] = \"Passport\"\n",
        "          data[\"country\"] = \"China\"\n",
        "\n",
        "          # Passport Number\n",
        "          match = re.search(r'\\bE\\d{8,9}\\b', joined)\n",
        "          if match:\n",
        "              data[\"passport_number\"] = match.group()\n",
        "\n",
        "          # English Name\n",
        "          name_match = re.search(r'\\n([A-Z]{2,})\\s+([A-Z]{2,})\\n', joined)\n",
        "          if name_match:\n",
        "              data[\"last_name\"] = name_match.group(1).title()\n",
        "              data[\"first_name\"] = name_match.group(2).title()\n",
        "\n",
        "          # Date of Birth\n",
        "          dob_match = re.search(r'Date of birth[^\\d]*(\\d{2} \\w{3} \\d{4})', joined, re.IGNORECASE)\n",
        "          if dob_match:\n",
        "              data[\"date_of_birth\"] = dob_match.group(1)\n",
        "\n",
        "          # Issue Date\n",
        "          issue_match = re.search(r'Date of issue[^\\d]*(\\d{2} \\w{3} \\d{4})', joined, re.IGNORECASE)\n",
        "          if issue_match:\n",
        "              data[\"issue_date\"] = issue_match.group(1)\n",
        "\n",
        "          # Expiry Date\n",
        "          expiry_match = re.search(r'expir[^\\d]*(\\d{2} \\w{3} \\d{4})', joined, re.IGNORECASE)\n",
        "          if expiry_match:\n",
        "              data[\"expiry_date\"] = expiry_match.group(1)\n",
        "\n",
        "          # Gender\n",
        "          if \"Â•≥\" in joined or \"/F\" in joined:\n",
        "              data[\"gender\"] = \"F\"\n",
        "          elif \"Áî∑\" in joined or \"/M\" in joined:\n",
        "              data[\"gender\"] = \"M\"\n",
        "\n",
        "          # Chinese name\n",
        "          for i, line in enumerate(lines):\n",
        "              if \"ÂßìÂêç\" in line and i + 1 < len(lines):\n",
        "                  if re.search(r'[\\u4e00-\\u9fff]', lines[i + 1]):\n",
        "                      data[\"chinese_name\"] = lines[i + 1].strip()\n",
        "\n",
        "          # Nationality\n",
        "          nat_match = re.search(r'(ÂõΩÁ±ç|Nationality)[^\\n]*\\n*([^\\n]+)', joined)\n",
        "          if nat_match:\n",
        "              raw_nat = nat_match.group(2)\n",
        "              eng_nat = re.search(r'\\b[A-Z]{3}\\b', raw_nat)\n",
        "              if eng_nat:\n",
        "                  data[\"nationality\"] = eng_nat.group()\n",
        "              else:\n",
        "                  data[\"nationality\"] = raw_nat.strip()\n",
        "\n",
        "          for k, v in data.items():\n",
        "              if isinstance(v, str):\n",
        "                  data[k] = v.replace('\\n', ' ').strip()\n",
        "\n",
        "          return data  # ‚úÖ Exit early for passport\n",
        "\n",
        "      # ---------------------\n",
        "      # Existing Chinese ID Card Logic (unchanged)\n",
        "      # ---------------------\n",
        "      if \"‰∏≠ÂõΩ\" in joined or \"CHINA\" in joined.upper():\n",
        "          data[\"country\"] = \"China\"\n",
        "\n",
        "      id_match = re.search(r'\\b\\d{17}[\\dXx]\\b', joined)\n",
        "      if id_match:\n",
        "          data[\"id_number\"] = id_match.group()\n",
        "\n",
        "      dob_match = re.search(r'(Âá∫ÁîüÊó•Êúü|Date of Birth)[^\\d]*(\\d{4}[./-]\\d{2}[./-]\\d{2})', joined)\n",
        "      if dob_match:\n",
        "          data[\"date_of_birth\"] = dob_match.group(2)\n",
        "\n",
        "      validity_match = re.search(r'(\\d{4}[./-]\\d{2}[./-]\\d{2})-(\\d{4}[./-]\\d{2}[./-]\\d{2})', joined)\n",
        "      if validity_match:\n",
        "          data[\"issue_date\"] = validity_match.group(1)\n",
        "          data[\"expiry_date\"] = validity_match.group(2)\n",
        "\n",
        "      gender_match = re.search(r'(ÊÄßÂà´|Sex)[^\\n]*\\n*([Áî∑Â•≥MF])/?([MFÁî∑Â•≥]?)', joined, re.IGNORECASE)\n",
        "      if gender_match:\n",
        "          g1 = gender_match.group(2).upper()\n",
        "          g2 = gender_match.group(3).upper()\n",
        "          gender_char = g1 if g1 in ['M', 'F'] else g2\n",
        "          if gender_char in ['M', 'Áî∑']:\n",
        "              data[\"gender\"] = \"M\"\n",
        "          elif gender_char in ['F', 'Â•≥']:\n",
        "              data[\"gender\"] = \"F\"\n",
        "\n",
        "      eng_name_match = re.search(r'[A-Z]{2,},\\s*[A-Z\\s]{2,}', joined)\n",
        "      if eng_name_match:\n",
        "          full_name = eng_name_match.group().splitlines()[0].strip()\n",
        "          parts = full_name.split(',')\n",
        "          if len(parts) == 2:\n",
        "              data[\"last_name\"] = parts[0].strip().title()\n",
        "              data[\"first_name\"] = parts[1].strip().title()\n",
        "\n",
        "      for i, line in enumerate(lines):\n",
        "          if re.search(r'(ÂßìÂêç|ÂßìÂêç/Name)', line):\n",
        "              if i + 1 < len(lines):\n",
        "                  chinese_name = lines[i + 1].strip()\n",
        "                  if re.search(r'[\\u4e00-\\u9fff]', chinese_name):\n",
        "                      data[\"chinese_name\"] = chinese_name\n",
        "\n",
        "      nat_match = re.search(r'(ÂõΩÁ±ç|Nationality)[^\\n]*\\n*([^\\n]+)', joined)\n",
        "      if nat_match:\n",
        "          raw_nat = nat_match.group(2)\n",
        "          eng_nat = re.search(r'\\b[A-Z]{3}\\b', raw_nat)\n",
        "          if eng_nat:\n",
        "              data[\"nationality\"] = eng_nat.group()\n",
        "          else:\n",
        "              data[\"nationality\"] = raw_nat.strip()\n",
        "\n",
        "      for k, v in data.items():\n",
        "          if isinstance(v, str):\n",
        "              data[k] = v.replace('\\n', ' ').strip()\n",
        "\n",
        "      return data\n",
        "\n",
        "    def extract_id_fields(text):\n",
        "        return extract_chinese_fields(text) if detect_language(text) == \"chinese\" else extract_pakistani_fields(text)\n",
        "\n",
        "    fields = extract_id_fields(full_text)\n",
        "    for k, v in fields.items():\n",
        "        if isinstance(v, str): fields[k] = v.replace('\\n', ' ').strip()\n",
        "\n",
        "    from datetime import datetime\n",
        "\n",
        "    # ---------------------------\n",
        "    # Convert Dates to ISO Format\n",
        "    # ---------------------------\n",
        "    def to_iso(date_str):\n",
        "        if not isinstance(date_str, str):\n",
        "            return date_str\n",
        "\n",
        "        cleaned = date_str.upper().strip().replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
        "\n",
        "        # Fix common OCR issues in month and day\n",
        "        replacements = {\n",
        "            \"10A\": \"10\",   # common OCR confusion\n",
        "            \"1O\": \"10\",    # 'O' instead of zero\n",
        "            \"OCTOBER\": \"OCT\", \"0CT\": \"OCT\", \"OCT\": \"OCT\",\n",
        "            \"JANUARY\": \"JAN\", \"JAN\": \"JAN\",\n",
        "            \"FEBRUARY\": \"FEB\", \"FEB\": \"FEB\",\n",
        "            \"MARCH\": \"MAR\", \"MAR\": \"MAR\",\n",
        "            \"APRIL\": \"APR\", \"APR\": \"APR\",\n",
        "            \"MAY\": \"MAY\",\n",
        "            \"JUNE\": \"JUN\", \"JUN\": \"JUN\",\n",
        "            \"JULY\": \"JUL\", \"JUL\": \"JUL\",\n",
        "            \"AUGUST\": \"AUG\", \"AUG\": \"AUG\",\n",
        "            \"SEPTEMBER\": \"SEP\", \"SEP\": \"SEP\",\n",
        "            \"NOVEMBER\": \"NOV\", \"NOV\": \"NOV\",\n",
        "            \"DECEMBER\": \"DEC\", \"DEC\": \"DEC\"\n",
        "        }\n",
        "\n",
        "        for wrong, right in replacements.items():\n",
        "            cleaned = cleaned.replace(wrong, right)\n",
        "\n",
        "        # Remove symbols like [ ] or stray punctuation\n",
        "        cleaned = re.sub(r\"[^\\w\\s:/-]\", \"\", cleaned)\n",
        "        cleaned = re.sub(r\"\\s+/\", \"/\", cleaned)\n",
        "\n",
        "        formats = [\n",
        "            \"%d %b %Y\", \"%d %B %Y\",\n",
        "            \"%d/%b/%Y\", \"%d/%B/%Y\",\n",
        "            \"%d %b/%Y\", \"%d %B/%Y\",\n",
        "            \"%d-%b-%Y\", \"%d-%B-%Y\",\n",
        "            \"%d/%m/%Y\", \"%d-%m-%Y\", \"%d.%m.%Y\",\n",
        "            \"%Y/%m/%d\", \"%Y-%m-%d\"\n",
        "        ]\n",
        "\n",
        "        for fmt in formats:\n",
        "            try:\n",
        "                return datetime.strptime(cleaned, fmt).strftime(\"%Y-%m-%d\")\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        return date_str\n",
        "\n",
        "\n",
        "    # ---------------------------\n",
        "    # Apply to Extracted Fields\n",
        "    # ---------------------------\n",
        "    for key in [\"date_of_birth\", \"issue_date\", \"expiry_date\"]:\n",
        "        if key in fields:\n",
        "            fields[key] = to_iso(fields[key])\n",
        "\n",
        "\n",
        "    # üîó Inject similarity result\n",
        "    if shared_result:\n",
        "        fields[\"face_match\"] = shared_result.get(\"match\")\n",
        "        fields[\"face_distance\"] = shared_result.get(\"distance\")\n",
        "        fields[\"face_similarity\"] = shared_result.get(\"similarity\")\n",
        "\n",
        "    print(\"\\n---- Final Extracted Fields ----\")\n",
        "    for k, v in fields.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "\n",
        "    # Save JSON\n",
        "    json_filename = os.path.splitext(os.path.basename(doc_image_path))[0] + \".json\"\n",
        "    output_path = os.path.join(\"/content/drive/MyDrive/proj\", json_filename)\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(fields, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\n‚úÖ Saved JSON to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "Kq4og6u8ZMcj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Run both threads\n",
        "# -----------------------------\n",
        "face_thread_handle = threading.Thread(target=face_thread)\n",
        "ocr_thread_handle = threading.Thread(target=ocr_thread)\n",
        "\n",
        "face_thread_handle.start()\n",
        "ocr_thread_handle.start()\n",
        "\n",
        "# Wait for both to finish\n",
        "face_thread_handle.join()\n",
        "ocr_thread_handle.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj2d1vtOZOwN",
        "outputId": "565c7ecc-d3ac-41ad-8dec-203fcb47ccf2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Could not load image: /content/drive/MyDrive/proj/target1.jpg\n",
            "‚ùå Face extraction failed.\n",
            "\n",
            "üìù Raw OCR Text saved to: /content/drive/MyDrive/proj/id_ocr_raw.txt\n",
            "\n",
            "---- OCR Extracted Text ----\n",
            "PAKISTAN National Identity Card\n",
            "ISLAMIC REPUBLIC OF PAKISTAN\n",
            "Name\n",
            "Hassaan Mustafa\n",
            "Father Name\n",
            "ÿ≠ÿ≥ÿßŸÜ ŸÖÿµÿ∑ŸÅ€í\n",
            "Muhammad Shafiq Rafiq\n",
            "23880\n",
            "Gender Country of Stay\n",
            "M\n",
            "Pakistan\n",
            "Identity Number\n",
            "35202-5836303-9\n",
            "Date of Issue\n",
            "02.12.2021\n",
            "ŸÖÿ≠ŸÖÿØ ÿ¥ŸÅ€åŸÇ ÿ±ŸÅ€åŸÇ\n",
            "Date of Birth\n",
            "06.10.2003\n",
            "Hass\n",
            "Date of Expiry\n",
            "02.12.2031\n",
            "Holder's Signature\n",
            "\n",
            "---- Final Extracted Fields ----\n",
            "document_type: ID Card\n",
            "nationality: Pakistan\n",
            "id_number: 35202-5836303-9\n",
            "gender: M\n",
            "date_of_birth: 06.10.2003\n",
            "issue_date: 02.12.2021\n",
            "expiry_date: 02.12.2031\n",
            "first_name: Hassaan\n",
            "last_name: Mustafa\n",
            "urdu_name: ÿ≠ÿ≥ÿßŸÜ ŸÖÿµÿ∑ŸÅ€í\n",
            "urdu_father_name: ŸÖÿ≠ŸÖÿØ ÿ¥ŸÅ€åŸÇ ÿ±ŸÅ€åŸÇ\n",
            "face_match: False\n",
            "face_distance: None\n",
            "face_similarity: None\n",
            "\n",
            "‚úÖ Saved JSON to: /content/drive/MyDrive/proj/id.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uOp4hHu2agC4"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}