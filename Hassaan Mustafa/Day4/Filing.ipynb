{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d0c9e3-3656-4283-99df-33c0316c7908",
   "metadata": {},
   "source": [
    "# os module â€“ File & Directory Operations\n",
    "\n",
    "**Q:1 Create, Read, Rename, Remove files and folder**\n",
    "\n",
    "**Q:1 Get the current working directory and navigate to a sibling directory**\n",
    "\n",
    "**Q:2 Recursively list all files in a directory using only os.**\n",
    "\n",
    "**Q:3 Check if a given path is a file, directory, or doesn't exist.**\n",
    "\n",
    "**Q:4 Create a deeply nested folder structure like**\n",
    "\n",
    "**Q:5 Delete all empty directories from a given folder tree.**\n",
    "\n",
    "**Q:6 Count the number of .txt files in a directory using os.listdir().**\n",
    "\n",
    "**Q:7 Move files from one folder to another, creating the destination if needed.**\n",
    "\n",
    "**Q:8 Rename all .log files to .log.bak within a folder.**\n",
    "\n",
    "**Q:9 Print the total size of all files in a directory in MB.**\n",
    "\n",
    "**Q:10 Print the directory tree with indentation (like the tree command).**\n",
    "\n",
    "**Q:11 Write a function that synchronizes the structure of two directory trees (mirror mode).**\n",
    "\n",
    "**Q:12 Implement a safe folder deletion function that first moves the folder to a Trash directory.**\n",
    "\n",
    "**Q13: Find and print the most recently modified file in a directory recursively.**\n",
    "\n",
    "**Q:14 Generate a directory report (file count, total size, subfolders) in JSON format.**\n",
    "\n",
    "**Q:15 Track changes (additions/removals) in a directory over time using file snapshots.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb604f0-de66-4950-b150-3ea858f1ba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'a', 'ananas.js', 'apple.js', 'banana.js', 'Filing.ipynb', 'glob_and_os.ipynb', 'img.jpg', 'main.py', 'name.txt']\n",
      "Hello there.\n"
     ]
    }
   ],
   "source": [
    "# Q1 Create, Read, Rename, Remove files and folder\n",
    "import os\n",
    "# create a file\n",
    "with open(\"name.txt\", \"w\") as file:\n",
    "    file.write(\"Hello there.\")\n",
    "file.close()\n",
    "print(os.listdir())\n",
    "\n",
    "# read a file\n",
    "content = open(\"name.txt\", \"r\")\n",
    "file_content = content.read()\n",
    "print(file_content)\n",
    "\n",
    "#remove a file\n",
    "#print(\"\\nNow removing file....\")\n",
    "#os.remove(\"name.txt\")\n",
    "#print(os.listdir())\n",
    "#os.rmdir(\"empyty_directory\") # removes all empty directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3de0b42-c67e-49e2-b0d9-225e9d3f9a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'curr_dir = os.getcwd()\\nprint(\"Current Working Directory: \",curr_dir)\\n\\nparent_dir = os.path.dirname(curr_dir)\\nprint(\"Parent Directory\", parent_dir)\\n\\nos.listdir(parent_dir)\\nsib_dir = \"Day4\"\\n\\nsib_dir_path = os.path.join(parent_dir, sib_dir)\\nprint(\"Sibling Directory Path\", sib_dir_path)\\n\\nos.chdir(sib_dir_path)\\nprint(os.getcwd())\\nprint(os.listdir())'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2 Get the current working directory and navigate to a sibling directory\n",
    "'''curr_dir = os.getcwd()\n",
    "print(\"Current Working Directory: \",curr_dir)\n",
    "\n",
    "parent_dir = os.path.dirname(curr_dir)\n",
    "print(\"Parent Directory\", parent_dir)\n",
    "\n",
    "os.listdir(parent_dir)\n",
    "sib_dir = \"Day4\"\n",
    "\n",
    "sib_dir_path = os.path.join(parent_dir, sib_dir)\n",
    "print(\"Sibling Directory Path\", sib_dir_path)\n",
    "\n",
    "os.chdir(sib_dir_path)\n",
    "print(os.getcwd())\n",
    "print(os.listdir())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9375de53-f7e0-4781-a449-6ad8eab91288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def list_all_files(filepath):\\n    for root, dirs, files in os.walk(filepath):\\n        for file in files:\\n            print(os.path.join(root, file))\\n\\nlist_all_files(os.getcwd())'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3: Recursively list all files in a directory using only os.\n",
    "'''def list_all_files(filepath):\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        for file in files:\n",
    "            print(os.path.join(root, file))\n",
    "            \n",
    "list_all_files(os.getcwd())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aff88b7-92de-4cf0-9452-cd880199e516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def checkPath(filepath):\\n    if os.path.isfile(filepath):\\n        print(\"Its a file\")\\n        return\\n\\n    elif os.path.isdir(filepath):\\n        print(\"Its a directory\")\\n\\n    else:\\n        print(\"It doesn\\'t exist.\")\\n\\ncheckPath(os.getcwd())'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4 Check if a given path is a file, directory, or doesn't exist.\n",
    "\"\"\"def checkPath(filepath):\n",
    "    if os.path.isfile(filepath):\n",
    "        print(\"Its a file\")\n",
    "        return\n",
    "     \n",
    "    elif os.path.isdir(filepath):\n",
    "        print(\"Its a directory\")\n",
    "        \n",
    "    else:\n",
    "        print(\"It doesn't exist.\")\n",
    "\n",
    "checkPath(os.getcwd())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe3144f-c8f8-464b-b0b0-c83a0079d9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s.makedirs(os.path.join(os.getcwd(), \"a/b/c\"))'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5 Create a deeply nested folder structure like.\n",
    "'''s.makedirs(os.path.join(os.getcwd(), \"a/b/c\"))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504a41f-193c-4ea9-849a-58df15a77f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def DelEmptyDir(filepath):\\n    for root, dirs, files in os.walk(filepath, topdown = False):\\n        if not dirs and not files:\\n            try:\\n                os.rmdir(filepath)\\n                print(\"Deleted Directory: \", filepath)\\n            except OSError as e:\\n                print(\"Failed to remove directory:\\n\", filepath, \"Error: \\n\", e)\\n\\nDelEmptyDir(os.getcwd())'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6 Delete all empty directories from a given folder tree.\n",
    "\"\"\"def DelEmptyDir(filepath):\n",
    "    for root, dirs, files in os.walk(filepath, topdown = False):\n",
    "        if not dirs and not files:\n",
    "            try:\n",
    "                os.rmdir(filepath)\n",
    "                print(\"Deleted Directory: \", filepath)\n",
    "            except OSError as e:\n",
    "                print(\"Failed to remove directory:\\n\", filepath, \"Error: \\n\", e)\n",
    "                \n",
    "DelEmptyDir(os.getcwd())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2337b-6b7b-49fe-9931-d7c591bc141b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\ndef Count_txt_files(filepath):\\n    count = 0\\n    for x in os.listdir(filepath):\\n        full_path = os.path.join(filepath, x)\\n        if os.path.isfile(full_path) and x.endswith(\".txt\"):\\n            count += 1\\n    return count\\n\\n\\nCount_txt_files(os.getcwd())'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7 Count the number of .txt files in a directory using os.listdir().\n",
    "'''import os\n",
    "def Count_txt_files(filepath):\n",
    "    count = 0\n",
    "    for x in os.listdir(filepath):\n",
    "        full_path = os.path.join(filepath, x)\n",
    "        if os.path.isfile(full_path) and x.endswith(\".txt\"):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "Count_txt_files(os.getcwd())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41c41b-7da5-45e5-bfdd-476e72724bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8 Move files from one folder to another, creating the destination if needed.\n",
    "import shutil\n",
    "def move_files(src_folder, dest_folder):\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "    for item in os.listdir(src_folder):\n",
    "        src_path = os.path.join(src_folder, item)\n",
    "        dest_path = os.path.join(dest_folder, item)\n",
    "\n",
    "        if os.path.isfile(src_path):\n",
    "            shutil.move(src_path, dest_path)\n",
    "            print(f\"Moved: {src_path} -> {dest_path}\")\n",
    "\n",
    "# Example usage\n",
    "#move_files(os.getcwd(), \"C:\\Users\\ADMIN\\Desktop\\Hassaan Docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26b0a2bb-3b00-4100-b845-86d5624a98c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def log_To_logbak(filepath):\\n    for file in os.listdir(filepath):\\n        if file.endswith(\".log\"):\\n            os.rename(file, file+\".bak\")\\n    print(os.listdir(filepath))\\n    return\\n\\nlog_To_logbak(os.getcwd())'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9 Rename all .log files to .log.bak within a folder.\n",
    "'''def log_To_logbak(filepath):\n",
    "    for file in os.listdir(filepath):\n",
    "        if file.endswith(\".log\"):\n",
    "            os.rename(file, file+\".bak\")\n",
    "    print(os.listdir(filepath))\n",
    "    return\n",
    "    \n",
    "log_To_logbak(os.getcwd())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04406f76-8c61-422d-b1dc-082d6b359127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66958"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10 Print the total size of all files in a directory in MB.\n",
    "def TotalFilesSize(filepath):\n",
    "    total = 0\n",
    "    for file in os.listdir(filepath):\n",
    "        total += os.path.getsize(os.path.join(filepath, file))\n",
    "    return total\n",
    "    \n",
    "TotalFilesSize(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2e636e-228e-43e5-8c2a-27b465e9f994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import os\\n\\ndef print_tree(path, indent=0):\\n    for item in os.listdir(path):\\n        print('  ' * indent + item)\\n        full_path = os.path.join(path, item)\\n        if os.path.isdir(full_path):\\n            print_tree(full_path, indent + 1)\\n\\nprint_tree(os.getcwd())\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q11 Print the directory tree with indentation (like the tree command).\n",
    "'''import os\n",
    "\n",
    "def print_tree(path, indent=0):\n",
    "    for item in os.listdir(path):\n",
    "        print('  ' * indent + item)\n",
    "        full_path = os.path.join(path, item)\n",
    "        if os.path.isdir(full_path):\n",
    "            print_tree(full_path, indent + 1)\n",
    "\n",
    "print_tree(os.getcwd())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae90520a-7168-4c28-ba04-e38cf6969d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12 Write a function that synchronizes the structure of two directory trees (mirror mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3825a-334a-4720-a341-f0ea1543e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13 Implement a safe folder deletion function that first moves the folder to a Trash directory.\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def safe_delete(folder_path, trash_dir='Trash'):\n",
    "    os.makedirs(trash_dir, exist_ok=True)\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"'{folder_path}' is not a valid folder.\")\n",
    "        return\n",
    "\n",
    "    base_name = os.path.basename(folder_path.rstrip(os.sep))\n",
    "    dest_path = os.path.join(trash_dir, base_name)\n",
    "    counter = 1\n",
    "    while os.path.exists(dest_path):\n",
    "        dest_path = os.path.join(trash_dir, f\"{base_name}_{counter}\")\n",
    "        counter += 1\n",
    "\n",
    "    shutil.move(folder_path, dest_path)\n",
    "    print(f\"Moved '{folder_path}' to '{dest_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b7d7a2-9ca3-41b0-9a2d-1c25512f9d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\n\\ndef find_latest_file(root_dir):\\n    latest_file = None\\n    latest_mtime = 0\\n\\n    for foldername, subfolders, filenames in os.walk(root_dir):\\n        for filename in filenames:\\n            filepath = os.path.join(foldername, filename)\\n            try:\\n                mtime = os.path.getmtime(filepath)\\n                if mtime > latest_mtime:\\n                    latest_mtime = mtime\\n                    latest_file = filepath\\n            except Exception as e:\\n                print(f\"Skipping file due to error: {filepath} ({e})\")\\n\\n    if latest_file:\\n        print(f\"Most recently modified file: {latest_file}\")\\n    else:\\n        print(\"No files found.\")\\n\\nfind_latest_file(\\'.\\')  '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q14 Find and print the most recently modified file in a directory recursively.\n",
    "'''import os\n",
    "\n",
    "def find_latest_file(root_dir):\n",
    "    latest_file = None\n",
    "    latest_mtime = 0\n",
    "\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            try:\n",
    "                mtime = os.path.getmtime(filepath)\n",
    "                if mtime > latest_mtime:\n",
    "                    latest_mtime = mtime\n",
    "                    latest_file = filepath\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping file due to error: {filepath} ({e})\")\n",
    "\n",
    "    if latest_file:\n",
    "        print(f\"Most recently modified file: {latest_file}\")\n",
    "    else:\n",
    "        print(\"No files found.\")\n",
    "\n",
    "find_latest_file('.')  '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e93ae0bf-78d0-4fb0-8a3e-df9e29b0596c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size(Bytes):  91767 \n",
      "File Count =  14 \n",
      "No.of SubFolders:  4\n"
     ]
    }
   ],
   "source": [
    "# Q15 Generate a directory report (file count, total size, sub-folders) in JSON format.\n",
    "def DirReport(filepath):\n",
    "    fileCount, totalSize, no_of_SubFolders = 0, 0, 0\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        for file in files:\n",
    "            fileCount += 1\n",
    "            totalSize += os.path.getsize(os.path.join(root, file))\n",
    "        for dir in dirs:\n",
    "            no_of_SubFolders += 1\n",
    "    \n",
    "    print(\"File size(Bytes): \", totalSize, \"\\nFile Count = \", fileCount, \"\\nNo.of SubFolders: \", no_of_SubFolders)\n",
    "    \n",
    "DirReport(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71c8615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q16 Track changes (additions/removals) in a directory over time using file snapshots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791d390-e204-4c7a-8169-792bf6d02fd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "# glob module â€“ Pattern Matching\n",
    "\n",
    "**Q:1 List all .csv and .json files in the current directory.**\n",
    "\n",
    "**Q:2 Recursively find all .jpg files in nested folders.**\n",
    "\n",
    "**Q:3 Use glob to count files grouped by extension.**\n",
    "\n",
    "**Q:4 Find files with names matching pattern report_*.txt.**\n",
    "\n",
    "**Q:5 Replace spaces with underscores in filenames found via glob.**\n",
    "\n",
    "**Q:6 Return all files with a date in the format 2025-06-*.log.**\n",
    "\n",
    "**Q:7 List all files with numeric names only (e.g., 123.txt).**\n",
    "\n",
    "**Q:8 Use glob to sort files by last modified time.**\n",
    "\n",
    "**Q:9 Find all .txt files larger than 100KB using glob and os.**\n",
    "\n",
    "**Q:10 Batch rename files with a custom suffix _archived.**\n",
    "\n",
    "**Q:11 Create a utility that indexes all media files and stores the paths in a SQLite DB.**\n",
    "\n",
    "**Q:12 Find duplicate filenames (regardless of path) across a directory tree.**\n",
    "\n",
    "**Q:13 Generate a file manifest with relative paths and hash (MD5) of contents.**\n",
    "\n",
    "**Q14: Use glob patterns dynamically to extract weekly reports (e.g., week_01.json, week_02.json).**\n",
    "\n",
    "**Q:15 Write a recursive file crawler that ignores folders listed in a .ignore file.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e086f083-8cf2-409a-99bc-423710252c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Q1 List all .csv and .json files in the current directory.\n",
    "import glob\n",
    "\n",
    "csv_files = glob.glob(\"*.csv\")\n",
    "json_files = glob.glob(\"*.json\")\n",
    "print(csv_files + json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645efcb6-eb26-4e68-b757-768e461d75d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Q2 Recursively find all .jpg files in nested folders.\n",
    "jpg_files = glob.glob(\"**/*.jpg\", recursive=True)\n",
    "print(jpg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7960eb22-6d5a-478d-ae2b-7313d61d601f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".js\n",
      ".js\n",
      ".js\n",
      ".ipynb\n",
      ".ipynb\n",
      ".jpg\n",
      ".py\n",
      ".log\n",
      ".txt\n",
      ".log\n",
      ".log\n",
      "{'.js': 3, '.ipynb': 2, '.jpg': 1, '.py': 1, '.log': 3, '.txt': 1}\n"
     ]
    }
   ],
   "source": [
    "# Q3 Use glob to count files grouped by extension.\n",
    "import os\n",
    "import glob\n",
    "\n",
    "file_counts = {}\n",
    "\n",
    "for file in glob.glob(\"*.*\"):\n",
    "    ext = os.path.splitext(file)[1]\n",
    "    print(ext)\n",
    "    if ext in file_counts:\n",
    "        file_counts[ext] += 1\n",
    "    else:\n",
    "        file_counts[ext] = 1\n",
    "\n",
    "print(file_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581ba6c-a002-4d46-91bd-1f7953f24f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Q4 Find files with names matching pattern report_*.txt.\n",
    "report_files = glob.glob(\"report_*.txt\")\n",
    "print(report_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ddb88a-132e-44ad-98a7-ef2889b90fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 Replace spaces with underscores in filenames found via glob.\n",
    "import os\n",
    "\n",
    "for file in glob.glob(\"* *\"):\n",
    "    new_name = file.replace(\" \", \"_\")\n",
    "    os.rename(file, new_name)\n",
    "    print(f\"Renamed: {file} -> {new_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6944a2-6a7e-4f31-a1d3-ea519703ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 Return all files with a date in the format 2025-06-*.log.\n",
    "log_files = glob.glob(\"2025-06-*.log\")\n",
    "print(log_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e02f22be-8e15-4438-b6f0-89171f2cbd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Q7 List all files with numeric names only (e.g., 123.txt).\n",
    "import glob\n",
    "\n",
    "numeric_files = []\n",
    "\n",
    "for f in glob.glob(\"*.txt\"):\n",
    "    name = f[:-4]  # remove .txt\n",
    "    if name.isdigit():\n",
    "        numeric_files.append(f)\n",
    "\n",
    "print(numeric_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1347debe-d3e6-435c-9419-7c83319ea167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filing.ipynb - Last modified: 1750837821.5899827\n",
      "main.py - Last modified: 1750766602.4887407\n",
      "papa.log - Last modified: 1750751785.3033202\n",
      "nana.log - Last modified: 1750751779.3332808\n",
      "mama.log - Last modified: 1750751774.889748\n",
      "name.txt - Last modified: 1750751409.2880757\n",
      "a - Last modified: 1750656234.9664116\n",
      "glob_and_os.ipynb - Last modified: 1750653787.273668\n",
      "ananas.js - Last modified: 1750315406.1507413\n",
      "banana.js - Last modified: 1750315397.8056579\n",
      "apple.js - Last modified: 1750315320.4020226\n",
      "img.jpg - Last modified: 1732025795.7561018\n"
     ]
    }
   ],
   "source": [
    "# Q8 Use glob to sort files by last modified time.\n",
    "import glob\n",
    "import os\n",
    "\n",
    "files = glob.glob(\"*\")  # or use \"*.txt\" for specific types\n",
    "files.sort(key=os.path.getmtime, reverse = True)\n",
    "\n",
    "for f in files:\n",
    "    print(f\"{f} - Last modified: {os.path.getmtime(f)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a4d87d4-a7ea-4926-b1f6-98b57ef14353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Q9 Find all .txt files larger than 100KB using glob and os.\n",
    "import glob\n",
    "import os\n",
    "\n",
    "large_txt_files = []\n",
    "\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    if os.path.getsize(file) > 100 * 1024:  # 100KB in bytes\n",
    "        large_txt_files.append(file)\n",
    "\n",
    "print(large_txt_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c8c4f5-ccca-4503-ab99-41e81d18576b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport glob\\n\\nfor file in glob.glob(\"*.*\"):  # or use \"*.txt\" for specific file types\\n    name, ext = os.path.splitext(file)\\n    new_name = f\"{name}_archived{ext}\"\\n    os.rename(file, new_name)\\n    print(f\"Renamed: {file} -> {new_name}\")\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10 Batch rename files with a custom suffix _archived.\n",
    "'''import os\n",
    "import glob\n",
    "\n",
    "for file in glob.glob(\"*.*\"):  # or use \"*.txt\" for specific file types\n",
    "    name, ext = os.path.splitext(file)\n",
    "    new_name = f\"{name}_archived{ext}\"\n",
    "    os.rename(file, new_name)\n",
    "    print(f\"Renamed: {file} -> {new_name}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ee706df-4370-4da5-a142-b95c9437caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11 Create a utility that indexes all media files and stores the paths in a SQLite DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9009881-91b6-499d-be9e-5b00becf893f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate filenames:\n"
     ]
    }
   ],
   "source": [
    "# Q12 Find duplicate filenames (regardless of path) across a directory tree.\n",
    "import os\n",
    "\n",
    "def find_duplicate_filenames(root_dir):\n",
    "    all_files = []\n",
    "    duplicates = []\n",
    "\n",
    "    for root, dirs, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename in all_files:\n",
    "                if filename not in duplicates:\n",
    "                    duplicates.append(filename)\n",
    "            else:\n",
    "                all_files.append(filename)\n",
    "\n",
    "    print(\"Duplicate filenames:\")\n",
    "    for name in duplicates:\n",
    "        print(name)\n",
    "\n",
    "find_duplicate_filenames(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8902d-f3a0-48ad-becb-b99163059561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13 Generate a file manifest with relative paths and hash (MD5) of contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b33b98-b54f-4513-a552-da8cdd53c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14: Use glob patterns dynamically to extract weekly reports (e.g., week_01.json, week_02.json).\n",
    "import glob\n",
    "weekly_reports = glob.glob(\"week_[0-9][0-9].json\")\n",
    "\n",
    "print(\"Weekly reports found:\")\n",
    "for report in weekly_reports:\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eca2f0-33d0-4cff-bc46-04ef2ec87b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q15 Write a recursive file crawler that ignores folders listed in a .ignore file.\n",
    "import os\n",
    "\n",
    "def read_ignore_file(ignore_file=\".ignore\"):\n",
    "    ignored = []\n",
    "    if os.path.exists(ignore_file):\n",
    "        with open(ignore_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    ignored.append(line)\n",
    "    return ignored\n",
    "\n",
    "def crawl_directory(path, ignored_dirs):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        keep_dirs = []\n",
    "        for d in dirs:\n",
    "            rel_path = os.path.relpath(os.path.join(root, d), path)\n",
    "            if rel_path not in ignored_dirs:\n",
    "                keep_dirs.append(d)\n",
    "        dirs[:] = keep_dirs\n",
    "        for file in files:\n",
    "            print(os.path.join(root, file))\n",
    "\n",
    "# Example usage\n",
    "ignored_dirs = read_ignore_file(\".ignore\")\n",
    "crawl_directory(\".\", ignored_dirs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11836593-dc92-44d0-953c-46ac17571473",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "# File Handling â€“ Text & Binary Files\n",
    "\n",
    "**Q:1 Count the number of lines in a file without loading it entirely.**\n",
    "\n",
    "**Q:2 Replace a specific word in a file and save it to a new file.**\n",
    "\n",
    "**Q:3 Append data to an existing file with a timestamp.**\n",
    "\n",
    "**Q:4 Read and print the first 10 lines of a file.**\n",
    "\n",
    "**Q:5 Write a list of dictionaries as CSV manually (without csv module).**\n",
    "\n",
    "**Q:6 Copy a binary file in chunks (e.g., image or PDF).**\n",
    "\n",
    "**Q:7 Write a function to compare two files and print the differing lines.**\n",
    "\n",
    "**Q:8 Safely read a file that may not exist using try-except.**\n",
    "\n",
    "**Q:9 Read a file using a specific encoding (e.g., UTF-16).**\n",
    "\n",
    "**Q:10 Detect and skip empty lines when reading a file.**\n",
    "\n",
    "**Q:11 Implement a log rotation mechanism: create log.txt, log_1.txt, etc. when size exceeds 1MB.**\n",
    "\n",
    "**Q:12 Build a file-based key-value store using JSON per line.**\n",
    "\n",
    "**Q:13 Implement version control: on every write, back up the previous version with a timestamp.**\n",
    "\n",
    "**Q:14 Create a reader that detects encoding using chardet or fallback encoding.**\n",
    "\n",
    "**Q:15 Convert a large log file into separate files per date based on timestamps in each line.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9fca21-d1a6-43c9-a323-ac90a2d11f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lines(filepath):\n",
    "    count = 0\n",
    "    with open(filepath, 'r') as f:\n",
    "        for _ in f:\n",
    "            count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c8888-d4f2-4ef3-a557-935b1c0153f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_word(src, dest, old_word, new_word):\n",
    "    with open(src, 'r') as f_in, open(dest, 'w') as f_out:\n",
    "        for line in f_in:\n",
    "            f_out.write(line.replace(old_word, new_word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366559c-111f-43cd-b9cf-d5a0a57951ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def append_with_timestamp(filepath, data):\n",
    "    with open(filepath, 'a') as f:\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        f.write(f\"[{timestamp}] {data}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb7999-c659-452c-a71f-7f49ca9f1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_first_10_lines(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        for i in range(10):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53751a3c-9427-4fe1-97b4-ecc3646dd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_as_csv(dicts, filepath):\n",
    "    if not dicts:\n",
    "        return\n",
    "    keys = dicts[0].keys()\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(','.join(keys) + '\\n')\n",
    "        for d in dicts:\n",
    "            f.write(','.join(str(d[k]) for k in keys) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f88dd-9e32-44fa-acc1-d5099df1cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_binary_file(src, dest, chunk_size=1024):\n",
    "    with open(src, 'rb') as f_in, open(dest, 'wb') as f_out:\n",
    "        while chunk := f_in.read(chunk_size):\n",
    "            f_out.write(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03611855-540e-4c06-b88a-9818bd7c4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_files(file1, file2):\n",
    "    with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "        for i, (line1, line2) in enumerate(zip(f1, f2), 1):\n",
    "            if line1 != line2:\n",
    "                print(f\"Line {i} differs:\\n  File1: {line1.strip()}\\n  File2: {line2.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9c5d25-b370-48a7-b94d-5d0cf1c2747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_read(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec443e-67c2-4aae-bf45-61348919674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_utf16(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-16') as f:\n",
    "        return f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711969f-5301-4867-b7b9-dba59247ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_skip_empty(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c9462-d5ca-4f95-953c-15c9c7136de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rotate_log(log_path='log.txt', max_size=1*1024*1024):\n",
    "    if os.path.exists(log_path) and os.path.getsize(log_path) > max_size:\n",
    "        i = 1\n",
    "        while os.path.exists(f\"log_{i}.txt\"):\n",
    "            i += 1\n",
    "        os.rename(log_path, f\"log_{i}.txt\")\n",
    "    open(log_path, 'a').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80361657-7f56-4534-b5f6-b7eee56ecc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_kv_store(filepath, key, value):\n",
    "    with open(filepath, 'a') as f:\n",
    "        f.write(json.dumps({key: value}) + '\\n')\n",
    "\n",
    "def read_kv_store(filepath):\n",
    "    store = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            store.update(json.loads(line))\n",
    "    return store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72e9a6-e186-4d1d-b8b5-f52b3b781d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "def write_with_backup(filepath, new_data):\n",
    "    if os.path.exists(filepath):\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        shutil.copy(filepath, f\"{filepath}.{timestamp}.bak\")\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876fee2-bf07-4bc1-aee4-e7720ee401bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "def read_with_detected_encoding(filepath, fallback='utf-8'):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        raw = f.read()\n",
    "        result = chardet.detect(raw)\n",
    "        encoding = result['encoding'] or fallback\n",
    "    return raw.decode(encoding, errors='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c941d47-d2a4-473e-b853-798bccd0d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def split_logs_by_date(logfile):\n",
    "    date_files = defaultdict(list)\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                date = line[:10]  # assumes format: YYYY-MM-DD...\n",
    "                date_files[date].append(line)\n",
    "    for date, lines in date_files.items():\n",
    "        with open(f\"{date}.log\", 'w') as out:\n",
    "            out.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b7b4dc-a5af-49a8-b1a6-2629376ed791",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "# JSON Handling â€“ json module\n",
    "\n",
    "**Q:1 Load JSON from a file and print a nested field (e.g., data[\"user\"][\"name\"]).**\n",
    "\n",
    "**Q:2 Write a Python dict to a file with pretty formatting.**\n",
    "\n",
    "**Q:3 Merge multiple JSON objects into a single file.**\n",
    "\n",
    "**Q:4 Convert a JSON array into CSV format.**\n",
    "\n",
    "**Q:5 Update a nested key inside a loaded JSON.**\n",
    "\n",
    "**Q:6 Create a function to pretty-print JSON from string input.**\n",
    "\n",
    "**Q:7 Safely load malformed JSON with exception handling.**\n",
    "\n",
    "**Q:8 Remove a key from each item in a JSON list and re-save.**\n",
    "\n",
    "**Q:9 Convert an object with datetime to a JSON string using a custom encoder.**\n",
    "\n",
    "**Q:10 Search for all values associated with a key in nested JSON.**\n",
    "\n",
    "**Q:11 Write a function to flatten deeply nested JSON into a flat dictionary.**\n",
    "\n",
    "**Q:12 Build a recursive JSON validator for required schema keys.**\n",
    "\n",
    "**Q:13 Convert a nested JSON into a pandas DataFrame with normalized columns.**\n",
    "\n",
    "**Q:14 Create a diff tool that compares two JSON files and shows key-level changes.**\n",
    "\n",
    "**Q:15 Handle and fix trailing commas in malformed JSON before parsing.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed1e4b-4790-418d-ba76-3fd3697603c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[\"user\"][\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945a883-853d-412f-b1eb-4696b812d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"user\": {\"name\": \"Hassaan\", \"age\": 22}}\n",
    "\n",
    "with open(\"output.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea19279-5e6b-4e2b-8b55-5f1afa5bf4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "files = [\"file1.json\", \"file2.json\"]\n",
    "merged = []\n",
    "\n",
    "for fname in files:\n",
    "    with open(fname) as f:\n",
    "        merged.append(json.load(f))\n",
    "\n",
    "with open(\"merged.json\", \"w\") as f:\n",
    "    json.dump(merged, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d69ea5-4a78-48b2-83e2-c02b21be9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "with open(\"data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(\"data.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=data[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca8311-ecec-4810-a343-fef73c3fdda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[\"user\"][\"name\"] = \"Updated Name\"\n",
    "\n",
    "with open(\"data.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9a5f6-031c-49d3-bbc5-165459650667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_json(json_str):\n",
    "    import json\n",
    "    parsed = json.loads(json_str)\n",
    "    print(json.dumps(parsed, indent=4))\n",
    "\n",
    "# Example\n",
    "pretty_print_json('{\"a\":1,\"b\":{\"c\":2}}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b99d1-d6e9-4fca-9c86-c9c62cb3d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"bad.json\") as f:\n",
    "        data = json.load(f)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error loading JSON: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3708f19-a270-4366-bd8e-6044a70d2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for item in data:\n",
    "    item.pop(\"unwanted_key\", None)\n",
    "\n",
    "with open(\"cleaned.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4462486-b8a9-492b-8c85-415a6869ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class DateTimeEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        return super().default(obj)\n",
    "\n",
    "data = {\"name\": \"Hassaan\", \"joined\": datetime.now()}\n",
    "json_str = json.dumps(data, cls=DateTimeEncoder, indent=4)\n",
    "print(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a38e81-21a8-4534-bf38-b56e602348cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_keys(data, target_key):\n",
    "    results = []\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if key == target_key:\n",
    "                results.append(value)\n",
    "            results.extend(find_all_keys(value, target_key))\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            results.extend(find_all_keys(item, target_key))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeaed10-eec5-450f-a8bb-ab3d9c200aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(y, prefix=''):\n",
    "    out = {}\n",
    "    if isinstance(y, dict):\n",
    "        for k, v in y.items():\n",
    "            out.update(flatten_json(v, f\"{prefix}{k}_\"))\n",
    "    elif isinstance(y, list):\n",
    "        for i, v in enumerate(y):\n",
    "            out.update(flatten_json(v, f\"{prefix}{i}_\"))\n",
    "    else:\n",
    "        out[prefix[:-1]] = y\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719153bf-475c-404e-ab37-4df1bae3355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_json(data, schema):\n",
    "    for key, value in schema.items():\n",
    "        if key not in data:\n",
    "            return False\n",
    "        if isinstance(value, dict):\n",
    "            if not isinstance(data[key], dict) or not validate_json(data[key], value):\n",
    "                return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3306548-70c6-4a3b-8977-93d0f632d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.json_normalize(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e231e-9fd0-41ea-a70d-0d0095e4665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_diff(json1, json2):\n",
    "    diffs = {}\n",
    "    keys = set(json1) | set(json2)\n",
    "    for key in keys:\n",
    "        if json1.get(key) != json2.get(key):\n",
    "            diffs[key] = {\"old\": json1.get(key), \"new\": json2.get(key)}\n",
    "    return diffs\n",
    "\n",
    "with open(\"file1.json\") as f1, open(\"file2.json\") as f2:\n",
    "    data1 = json.load(f1)\n",
    "    data2 = json.load(f2)\n",
    "\n",
    "print(json_diff(data1, data2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb0524-fa1d-4cc8-99e6-c52f55e6f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def fix_trailing_commas(json_str):\n",
    "    json_str = re.sub(r\",\\s*([}\\]])\", r\"\\1\", json_str)\n",
    "    return json_str\n",
    "\n",
    "with open(\"bad.json\") as f:\n",
    "    raw = f.read()\n",
    "\n",
    "try:\n",
    "    fixed = fix_trailing_commas(raw)\n",
    "    data = json.loads(fixed)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Still malformed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3083804d-5685-4ed0-852d-40333ae26433",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "    \n",
    "# Regular Expressions â€“ re module\n",
    "\n",
    "**Q:1 Extract email addresses from a string using re.findall().**\n",
    "\n",
    "**Q:2 Validate a US phone number using regex.**\n",
    "\n",
    "**Q:3 Extract hashtags from a tweet-like string.**\n",
    "\n",
    "**Q:4 Replace all numbers with # in a paragraph.**\n",
    "\n",
    "**Q:5 Match filenames with extension .pdf, .docx, or .xlsx.**\n",
    "\n",
    "**Q:6 Split a paragraph into sentences using regex.**\n",
    "\n",
    "**Q:7 Match a date in the format DD-MM-YYYY or YYYY/MM/DD.**\n",
    "\n",
    "**Q:8 Extract quoted strings from text (e.g., \"like this\").**\n",
    "\n",
    "**Q:9 Clean a text by removing special characters except alphanumerics and spaces.**\n",
    "\n",
    "**Q:10 Capture repeated words like the the, is is in a sentence.**\n",
    "\n",
    "**Q:11 Write a regex that extracts values from key-value pairs (key: value) even if keys contain spaces.**\n",
    "\n",
    "**Q:12 Extract nested parentheses using recursive regex (advanced feature).**\n",
    "\n",
    "**Q:13 Create a regex to detect and fix malformed URLs in a text block.**\n",
    "\n",
    "**Q:14 Build a pattern to extract address-like strings (e.g., 123 Main St, City, ZIP).**\n",
    "\n",
    "**Q:15 Tokenize a log line into timestamp, level, and message using regex groups.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26db1f6-d95e-4acf-9865-f30af739bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = \"Contact us at support@example.com or hr@company.org\"\n",
    "emails = re.findall(r'\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b', text)\n",
    "print(emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5434d-35b9-4115-b333-ace145a2bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'^(?:\\(\\d{3}\\)\\s?|\\d{3}[-.\\s]?)\\d{3}[-.\\s]?\\d{4}$'\n",
    "\n",
    "def is_valid_us_phone(number):\n",
    "    return bool(re.fullmatch(pattern, number))\n",
    "\n",
    "print(is_valid_us_phone(\"123-456-7890\"))  # True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661df70d-da86-4263-9964-a6ac85f13087",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"Loving the #Python and #AI revolution! #CodeNewbie\"\n",
    "hashtags = re.findall(r'#\\w+', tweet)\n",
    "print(hashtags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d06c91-2baa-4cc3-b919-d5b66e479ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"There are 12 apples and 30 oranges.\"\n",
    "result = re.sub(r'\\d+', '#', text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b77dc7-10d4-4dd3-bff1-96221bf711cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"report.pdf\", \"data.xlsx\", \"notes.txt\", \"resume.docx\"]\n",
    "matched = [f for f in files if re.search(r'\\.(pdf|docx|xlsx)$', f)]\n",
    "print(matched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56308ae4-1cba-4d32-93a3-6c0b6ec54047",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello! How are you? I'm fine. Thanks.\"\n",
    "sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b8c6c-eb88-4d2a-9ca9-a1f1fb3ace9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Dates: 12-06-2024 and 2023/11/09\"\n",
    "dates = re.findall(r'\\b\\d{2}-\\d{2}-\\d{4}\\b|\\b\\d{4}/\\d{2}/\\d{2}\\b', text)\n",
    "print(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae3d300-1edc-48ed-8989-5a324c4e6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'He said \"hello\" and then she replied \"hi\".'\n",
    "quotes = re.findall(r'\"(.*?)\"', text)\n",
    "print(quotes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2451580-9fd8-4352-95dc-712a1bc956f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello! @User #1: This is %amazing$.\"\n",
    "cleaned = re.sub(r'[^A-Za-z0-9 ]+', '', text)\n",
    "print(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb494a-144b-4a43-8213-519acf6e04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is is a test to find the the repeated repeated words.\"\n",
    "repeats = re.findall(r'\\b(\\w+)\\s+\\1\\b', text)\n",
    "print(repeats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66d7a7-5d04-41d0-b569-28c958a0c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Name: John Doe, Age: 30, Location: New York\"\n",
    "pairs = re.findall(r'([\\w\\s]+):\\s*([^,]+)', text)\n",
    "print(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26419d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python's re module doesn't support true recursion, but this handles simple cases:\n",
    "text = \"Example (with (nested) parentheses)\"\n",
    "matches = re.findall(r'\\([^()]*\\)', text)\n",
    "print(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b320cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Visit http//example.com and www.test.com for more info.\"\n",
    "fixed = re.sub(r'(?<!https:)(?<!http:)//', r'http://', text)\n",
    "urls = re.findall(r'https?://\\S+|www\\.\\S+', fixed)\n",
    "print(urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Send mail to 123 Main St, Springfield, 12345 or 56 Oak Ave, LA, 90001.\"\n",
    "addresses = re.findall(r'\\d+\\s[\\w\\s]+,\\s*\\w+,\\s*\\d{5}', text)\n",
    "print(addresses)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
